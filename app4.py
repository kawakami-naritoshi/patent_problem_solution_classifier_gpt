import streamlit as st
import pandas as pd
import time
from datetime import datetime
import io
from openai import OpenAI
import pickle
import os
import re

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="PatentScope AI",
    page_icon="ğŸ”¬",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ãƒ¬ãƒ¼ãƒˆåˆ¶é™è¨­å®šï¼ˆGPT-4o-miniç”¨ï¼‰
RATE_LIMIT_DELAY = 1.0  # GPT-4o-miniã¯é«˜ã„ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã®ãŸã‚çŸ­ç¸®
BATCH_SIZE = 50  # ãƒãƒƒãƒå‡¦ç†ã‚µã‚¤ã‚º
CHECKPOINT_FILE = "checkpoint.pkl"  # ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
if 'processing_state' not in st.session_state:
    st.session_state.processing_state = None
if 'current_batch' not in st.session_state:
    st.session_state.current_batch = 0
if 'processed_data' not in st.session_state:
    st.session_state.processed_data = None

# ãƒ¡ã‚¤ãƒ³ãƒ˜ãƒƒãƒ€ãƒ¼
st.title("ğŸ”¬ PatentScope AI")
st.subheader("æ¬¡ä¸–ä»£ç‰¹è¨±åˆ†æãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ  - AIé§†å‹•å‹çŸ¥è²¡ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ã‚¹")

# æ”¹å–„ç‚¹ã®èª¬æ˜
with st.expander("ğŸ”§ å®‰å®šæ€§å‘ä¸Šæ©Ÿèƒ½", expanded=False):
    st.markdown("### âœ¨ æ–°æ©Ÿèƒ½")
    st.markdown("""
    - **GPT-4o-miniæ¡ç”¨**: é«˜é€Ÿãƒ»é«˜ç²¾åº¦ãªåˆ†é¡å‡¦ç†
    - **ãƒãƒƒãƒå‡¦ç†**: å¤§é‡ãƒ‡ãƒ¼ã‚¿ã‚’å°åˆ†ã‘ã—ã¦å‡¦ç†
    - **ä¸­æ–­ãƒ»å†é–‹æ©Ÿèƒ½**: å‡¦ç†ä¸­æ–­æ™‚ã‚‚ç¶šãã‹ã‚‰å†é–‹å¯èƒ½
    - **ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°**: API ã‚¨ãƒ©ãƒ¼æ™‚ã®è‡ªå‹•ãƒªãƒˆãƒ©ã‚¤
    - **ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ä¿å­˜**: å‡¦ç†çŠ¶æ³ã®è‡ªå‹•ä¿å­˜
    - **ãƒ¬ãƒ¼ãƒˆåˆ¶é™æœ€é©åŒ–**: GPT-4o-miniç”¨ã«é«˜é€ŸåŒ–ï¼ˆ1ç§’é–“éš”ï¼‰
    - **åˆ†é¡çµæœæ¤œè¨¼**: å®šç¾©ã•ã‚ŒãŸåˆ†é¡ã‚«ãƒ†ã‚´ãƒªã¨ã®ä¸€è‡´ã‚’ãƒã‚§ãƒƒã‚¯
    """)

# åˆ†é¡å®šç¾©ã‹ã‚‰æœ‰åŠ¹ãªã‚«ãƒ†ã‚´ãƒªã‚’æŠ½å‡ºã™ã‚‹é–¢æ•°
def extract_valid_categories(classification_def):
    """åˆ†é¡å®šç¾©ã‹ã‚‰æœ‰åŠ¹ãªã‚«ãƒ†ã‚´ãƒªåã‚’æŠ½å‡º"""
    categories = []
    lines = classification_def.strip().split('\n')
    for line in lines:
        # [ã‚«ãƒ†ã‚´ãƒªå] å½¢å¼ã‚’æŠ½å‡º
        match = re.match(r'\[([^\]]+)\]', line.strip())
        if match:
            categories.append(match.group(1))
    return categories

# åˆ†é¡çµæœã‚’æ¤œè¨¼ã™ã‚‹é–¢æ•°
def validate_classification_results(df, problem_categories, solution_categories):
    """åˆ†é¡çµæœã‚’æ¤œè¨¼ã—ã€å•é¡Œã®ã‚ã‚‹è¡Œã‚’ç‰¹å®š"""
    invalid_rows = {
        'problem': [],
        'solution': [],
        'both': []
    }
    
    for idx, row in df.iterrows():
        problem_valid = True
        solution_valid = True
        
        # èª²é¡Œåˆ†é¡ã®ãƒã‚§ãƒƒã‚¯
        if pd.notna(row.get('èª²é¡Œåˆ†é¡', '')):
            p_class = str(row['èª²é¡Œåˆ†é¡']).strip()
            if (p_class == "" or 
                p_class.startswith("ã‚¨ãƒ©ãƒ¼:") or 
                p_class == "è©²å½“ã™ã‚‹ã‚«ãƒ†ã‚´ãƒªã¯ã‚ã‚Šã¾ã›ã‚“" or
                p_class not in problem_categories):
                problem_valid = False
                invalid_rows['problem'].append({
                    'index': idx + 1,  # 1-based index for display
                    'value': p_class,
                    'summary': row.get('è¦ç´„', '')[:50] + '...' if len(str(row.get('è¦ç´„', ''))) > 50 else row.get('è¦ç´„', '')
                })
        
        # è§£æ±ºæ‰‹æ®µåˆ†é¡ã®ãƒã‚§ãƒƒã‚¯
        if pd.notna(row.get('è§£æ±ºæ‰‹æ®µåˆ†é¡', '')):
            s_class = str(row['è§£æ±ºæ‰‹æ®µåˆ†é¡']).strip()
            if (s_class == "" or 
                s_class.startswith("ã‚¨ãƒ©ãƒ¼:") or 
                s_class == "è©²å½“ã™ã‚‹ã‚«ãƒ†ã‚´ãƒªã¯ã‚ã‚Šã¾ã›ã‚“" or
                s_class not in solution_categories):
                solution_valid = False
                invalid_rows['solution'].append({
                    'index': idx + 1,
                    'value': s_class,
                    'summary': row.get('è¦ç´„', '')[:50] + '...' if len(str(row.get('è¦ç´„', ''))) > 50 else row.get('è¦ç´„', '')
                })
        
        # ä¸¡æ–¹ç„¡åŠ¹ãªå ´åˆ
        if not problem_valid and not solution_valid:
            invalid_rows['both'].append(idx + 1)
    
    return invalid_rows

# ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆå¾©æ—§æ©Ÿèƒ½
def save_checkpoint(data, batch_num, stage):
    """å‡¦ç†çŠ¶æ³ã‚’ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã¨ã—ã¦ä¿å­˜"""
    checkpoint = {
        'data': data,
        'batch_num': batch_num,
        'stage': stage,
        'timestamp': datetime.now()
    }
    with open(CHECKPOINT_FILE, 'wb') as f:
        pickle.dump(checkpoint, f)

def load_checkpoint():
    """ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰å¾©æ—§"""
    if os.path.exists(CHECKPOINT_FILE):
        try:
            with open(CHECKPOINT_FILE, 'rb') as f:
                return pickle.load(f)
        except:
            return None
    return None

def cleanup_checkpoint():
    """ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤"""
    if os.path.exists(CHECKPOINT_FILE):
        os.remove(CHECKPOINT_FILE)

# ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š
with st.sidebar:
    st.header("âš™ï¸ è¨­å®š")
    
    # APIã‚­ãƒ¼å…¥åŠ›
    st.subheader("ğŸ”‘ OpenAI APIè¨­å®š")
    api_key = st.text_input(
        "APIã‚­ãƒ¼",
        type="password",
        help="OpenAI Platform (https://platform.openai.com/api-keys) ã§å–å¾—ã§ãã¾ã™"
    )
    
    if api_key:
        st.success("APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¾ã—ãŸ âœ…")
        # OpenAI ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
        client = OpenAI(api_key=api_key)
    else:
        st.warning("APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
        client = None
    
    # ãƒãƒƒãƒã‚µã‚¤ã‚ºè¨­å®š
    st.subheader("âš™ï¸ å‡¦ç†è¨­å®š")
    batch_size = st.slider("ãƒãƒƒãƒã‚µã‚¤ã‚º", 10, 100, BATCH_SIZE, 10)
    st.info(f"ãƒ‡ãƒ¼ã‚¿ã‚’{batch_size}ä»¶ãšã¤å‡¦ç†ã—ã¾ã™")
    
    # ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆç®¡ç†
    st.subheader("ğŸ’¾ å¾©æ—§æ©Ÿèƒ½")
    checkpoint = load_checkpoint()
    if checkpoint:
        st.warning(f"âš ï¸ æœªå®Œäº†ã®å‡¦ç†ãŒã‚ã‚Šã¾ã™")
        st.info(f"æ™‚åˆ»: {checkpoint['timestamp'].strftime('%Y-%m-%d %H:%M:%S')}")
        st.info(f"ãƒãƒƒãƒ: {checkpoint['batch_num']}")
        
        col1, col2 = st.columns(2)
        with col1:
            if st.button("ğŸ”„ å‡¦ç†ã‚’å†é–‹", type="primary"):
                st.session_state.processing_state = checkpoint
                st.rerun()
        with col2:
            if st.button("ğŸ—‘ï¸ ãƒªã‚»ãƒƒãƒˆ"):
                cleanup_checkpoint()
                st.rerun()

# åˆ†é¡å®šç¾©å…¥åŠ›ï¼ˆå…ƒã®ã‚³ãƒ¼ãƒ‰ã¨åŒã˜ï¼‰
col1, col2 = st.columns([1, 1])

with col1:
    st.subheader("ğŸ“ èª²é¡Œåˆ†é¡å®šç¾©ã®å…¥åŠ›")
    problem_classification = st.text_area(
        "èª²é¡Œåˆ†é¡ã‚«ãƒ†ã‚´ãƒª",
        value="""[ãƒ¢ãƒ¼ã‚¿åŠ¹ç‡ãƒ»æ€§èƒ½å‘ä¸Š] èª¬æ˜æ–‡: é›»æ°—ãƒ¢ãƒ¼ã‚¿ã®åŠ¹ç‡æ”¹å–„ã€å°å‹åŒ–...""",
        height=200,
        key="problem_def"
    )

with col2:
    st.subheader("ğŸ”§ è§£æ±ºæ‰‹æ®µåˆ†é¡å®šç¾©ã®å…¥åŠ›")
    solution_classification = st.text_area(
        "è§£æ±ºæ‰‹æ®µåˆ†é¡ã‚«ãƒ†ã‚´ãƒª",
        value="""[ãƒ¢ãƒ¼ã‚¿æ§‹é€ ã®æœ€é©åŒ–] èª¬æ˜æ–‡: ãƒ–ãƒ©ã‚·ãƒ¬ã‚¹ãƒ¢ãƒ¼ã‚¿ã®ãƒ­ãƒ¼ã‚¿...""",
        height=200,
        key="solution_def"
    )

# ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
st.subheader("ğŸ“ ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
uploaded_file = st.file_uploader(
    "Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„",
    type=['xlsx'],
    help="ã€Œè¦ç´„ã€åˆ—ã‚’å«ã‚€Excelãƒ•ã‚¡ã‚¤ãƒ« (.xlsx) ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„"
)

# æ”¹è‰¯ã•ã‚ŒãŸåˆ†é¡å‡¦ç†é–¢æ•°
def generate_classification_with_retry(text, classification_def, classification_type, client, max_retries=3):
    """ãƒªãƒˆãƒ©ã‚¤æ©Ÿèƒ½ä»˜ãåˆ†é¡å‡¦ç†ï¼ˆGPT-4o-miniç”¨ï¼‰"""
    for attempt in range(max_retries):
        try:
            if classification_type == "problem":
                prompt = f"""##Task: Classify the input problem description into one of the problem categories below. You MUST select the most appropriate category from the list. Do not answer "è©²å½“ã™ã‚‹ã‚«ãƒ†ã‚´ãƒªã¯ã‚ã‚Šã¾ã›ã‚“" or similar. Output only the category name in Japanese WITHOUT square brackets [].

##Problem Categories: {classification_def}

##Instructions:
1. Read the input description carefully
2. Compare it with ALL categories
3. Select the MOST appropriate category (even if not perfect match)
4. Output ONLY the category name without brackets []
5. Answer in Japanese only

##Input: {text}

##Answer (category name only, no brackets):"""
            else:
                prompt = f"""##Task: Classify the input solution description into one of the solution categories below. You MUST select the most appropriate category from the list. Do not answer "è©²å½“ã™ã‚‹ã‚«ãƒ†ã‚´ãƒªã¯ã‚ã‚Šã¾ã›ã‚“" or similar. Output only the category name in Japanese WITHOUT square brackets [].

##Solution Categories: {classification_def}

##Instructions:
1. Read the input description carefully
2. Compare it with ALL categories
3. Select the MOST appropriate category (even if not perfect match)
4. Output ONLY the category name without brackets []
5. Answer in Japanese only

##Input: {text}

##Answer (category name only, no brackets):"""
            
            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "user", "content": prompt}
                ],
                max_tokens=50,
                temperature=0.1
            )
            
            result = response.choices[0].message.content.strip()
            
            # []æ‹¬å¼§ãŒã‚ã‚‹å ´åˆã¯é™¤å»
            if result.startswith('[') and result.endswith(']'):
                result = result[1:-1]
            
            return result
            
        except Exception as e:
            if attempt < max_retries - 1:
                st.warning(f"API ã‚¨ãƒ©ãƒ¼ (è©¦è¡Œ {attempt + 1}): {str(e)} - ãƒªãƒˆãƒ©ã‚¤ã—ã¾ã™...")
                time.sleep(2 ** attempt)  # æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•
            else:
                return f"åˆ†é¡ã‚¨ãƒ©ãƒ¼: {str(e)}"

def process_batch(df_batch, start_idx, problem_def, solution_def, stage, client):
    """ãƒãƒƒãƒå‡¦ç†"""
    batch_results = []
    
    for i, (idx, row) in enumerate(df_batch.iterrows()):
        current_idx = start_idx + i
        
        try:
            if stage in ['problem', 'both']:
                # èª²é¡Œåˆ†é¡
                p_class = generate_classification_with_retry(
                    row['è¦ç´„'], problem_def, "problem", client
                )
                batch_results.append({
                    'index': idx,
                    'problem_class': p_class,
                    'solution_class': None
                })
            
            if stage in ['solution', 'both']:
                # è§£æ±ºæ‰‹æ®µåˆ†é¡
                s_class = generate_classification_with_retry(
                    row['è¦ç´„'], solution_def, "solution", client
                )
                
                if stage == 'solution' and batch_results:
                    batch_results[i]['solution_class'] = s_class
                elif stage == 'both':
                    batch_results[i]['solution_class'] = s_class
                else:
                    batch_results.append({
                        'index': idx,
                        'problem_class': None,
                        'solution_class': s_class
                    })
            
            # ãƒ¬ãƒ¼ãƒˆåˆ¶é™
            time.sleep(RATE_LIMIT_DELAY)
            
        except Exception as e:
            st.error(f"è¡Œ {current_idx} ã§ã‚¨ãƒ©ãƒ¼: {str(e)}")
            batch_results.append({
                'index': idx,
                'problem_class': f"ã‚¨ãƒ©ãƒ¼: {str(e)}",
                'solution_class': f"ã‚¨ãƒ©ãƒ¼: {str(e)}"
            })
    
    return batch_results

if uploaded_file is not None:
    try:
        df = pd.read_excel(uploaded_file)
        
        if 'è¦ç´„' not in df.columns:
            st.error("âŒ ã‚¨ãƒ©ãƒ¼: ã€Œè¦ç´„ã€åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        else:
            st.success("âœ… ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿å®Œäº†")
            st.info(f"{len(df)}è¡Œã®ãƒ‡ãƒ¼ã‚¿ãŒèª­ã¿è¾¼ã¾ã‚Œã¾ã—ãŸ")
            
            # ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
            with st.expander("ğŸ“Š ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼", expanded=False):
                st.dataframe(df.head(10), use_container_width=True)
            
            # å‡¦ç†æ™‚é–“ã®æ¨å®š
            total_batches = (len(df) + batch_size - 1) // batch_size
            estimated_time = len(df) * RATE_LIMIT_DELAY * 2 / 60  # GPT-4o-miniç”¨ã®çŸ­ç¸®æ™‚é–“
            
            st.subheader("ğŸš€ åˆ†é¡å‡¦ç†")
            st.info(f"ğŸ“Š ç·ãƒ‡ãƒ¼ã‚¿æ•°: {len(df)}ä»¶")
            st.info(f"ğŸ“¦ ãƒãƒƒãƒæ•°: {total_batches}ãƒãƒƒãƒ")
            st.info(f"â±ï¸ æ¨å®šå‡¦ç†æ™‚é–“: ç´„{estimated_time:.1f}åˆ†")
            
            # å‡¦ç†é–‹å§‹ãƒœã‚¿ãƒ³
            if st.button("ğŸš€ åˆ†é¡å‡¦ç†é–‹å§‹", type="primary", disabled=not client):
                if not client:
                    st.error("âŒ APIã‚­ãƒ¼ãŒå¿…è¦ã§ã™")
                else:
                    # å‡¦ç†çŠ¶æ³ã®è¡¨ç¤º
                    progress_container = st.container()
                    log_container = st.empty()
                    
                    with progress_container:
                        progress_bar = st.progress(0)
                        status_text = st.empty()
                        batch_info = st.empty()
                    
                    try:
                        # çµæœæ ¼ç´ç”¨ã®åˆ—ã‚’åˆæœŸåŒ–
                        if 'èª²é¡Œåˆ†é¡' not in df.columns:
                            df['èª²é¡Œåˆ†é¡'] = ""
                        if 'è§£æ±ºæ‰‹æ®µåˆ†é¡' not in df.columns:
                            df['è§£æ±ºæ‰‹æ®µåˆ†é¡'] = ""
                        
                        start_time = datetime.now()
                        
                        # ãƒãƒƒãƒå‡¦ç†ãƒ«ãƒ¼ãƒ—
                        for batch_num in range(total_batches):
                            start_idx = batch_num * batch_size
                            end_idx = min(start_idx + batch_size, len(df))
                            df_batch = df.iloc[start_idx:end_idx]
                            
                            # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹æ›´æ–°
                            progress = (batch_num / total_batches)
                            progress_bar.progress(progress)
                            status_text.text(f"ãƒãƒƒãƒ {batch_num + 1}/{total_batches} å‡¦ç†ä¸­...")
                            batch_info.info(f"ğŸ“¦ ç¾åœ¨ã®ãƒãƒƒãƒ: {start_idx + 1}ï½{end_idx}è¡Œç›®")
                            
                            # ãƒãƒƒãƒå‡¦ç†å®Ÿè¡Œ
                            batch_results = process_batch(
                                df_batch, start_idx, 
                                problem_classification, 
                                solution_classification, 
                                'both',
                                client
                            )
                            
                            # çµæœã‚’ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«åæ˜ 
                            for result in batch_results:
                                idx = result['index']
                                if result['problem_class'] is not None:
                                    df.at[idx, 'èª²é¡Œåˆ†é¡'] = result['problem_class']
                                if result['solution_class'] is not None:
                                    df.at[idx, 'è§£æ±ºæ‰‹æ®µåˆ†é¡'] = result['solution_class']
                            
                            # ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜
                            save_checkpoint(df, batch_num + 1, 'both')
                            
                            # ãƒ­ã‚°æ›´æ–°
                            elapsed_time = (datetime.now() - start_time).total_seconds() / 60
                            log_container.info(f"ãƒãƒƒãƒ {batch_num + 1} å®Œäº† (çµŒéæ™‚é–“: {elapsed_time:.1f}åˆ†)")
                        
                        # å‡¦ç†å®Œäº†
                        progress_bar.progress(1.0)
                        total_time = (datetime.now() - start_time).total_seconds() / 60
                        status_text.success(f"âœ… å…¨å‡¦ç†å®Œäº†ï¼ (å‡¦ç†æ™‚é–“: {total_time:.1f}åˆ†)")
                        
                        # ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
                        cleanup_checkpoint()
                        
                        # åˆ†é¡çµæœã®æ¤œè¨¼
                        st.header("ğŸ” åˆ†é¡çµæœã®æ¤œè¨¼")
                        
                        # æœ‰åŠ¹ãªã‚«ãƒ†ã‚´ãƒªã‚’æŠ½å‡º
                        problem_categories = extract_valid_categories(problem_classification)
                        solution_categories = extract_valid_categories(solution_classification)
                        
                        # æ¤œè¨¼å®Ÿè¡Œ
                        invalid_rows = validate_classification_results(df, problem_categories, solution_categories)
                        
                        # æ¤œè¨¼çµæœã®è¡¨ç¤º
                        total_invalid = len(invalid_rows['problem']) + len(invalid_rows['solution'])
                        
                        if total_invalid == 0:
                            st.success("âœ… ã™ã¹ã¦ã®åˆ†é¡ãŒæ­£ã—ãä»˜ä¸ã•ã‚Œã¦ã„ã¾ã™ï¼")
                        else:
                            st.error(f"âš ï¸ {total_invalid}ä»¶ã®åˆ†é¡ã«å•é¡ŒãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ")
                            
                            # å•é¡Œã®è©³ç´°è¡¨ç¤º
                            col1, col2 = st.columns(2)
                            
                            with col1:
                                if invalid_rows['problem']:
                                    st.error(f"âŒ èª²é¡Œåˆ†é¡ã®å•é¡Œ: {len(invalid_rows['problem'])}ä»¶")
                                    with st.expander("è©³ç´°ã‚’è¡¨ç¤º", expanded=True):
                                        for item in invalid_rows['problem'][:10]:  # æœ€åˆã®10ä»¶ã®ã¿è¡¨ç¤º
                                            st.write(f"**è¡Œ {item['index']}**: '{item['value']}'")
                                            st.write(f"è¦ç´„: {item['summary']}")
                                            st.divider()
                                        if len(invalid_rows['problem']) > 10:
                                            st.info(f"ä»– {len(invalid_rows['problem']) - 10}ä»¶...")
                            
                            with col2:
                                if invalid_rows['solution']:
                                    st.error(f"âŒ è§£æ±ºæ‰‹æ®µåˆ†é¡ã®å•é¡Œ: {len(invalid_rows['solution'])}ä»¶")
                                    with st.expander("è©³ç´°ã‚’è¡¨ç¤º", expanded=True):
                                        for item in invalid_rows['solution'][:10]:
                                            st.write(f"**è¡Œ {item['index']}**: '{item['value']}'")
                                            st.write(f"è¦ç´„: {item['summary']}")
                                            st.divider()
                                        if len(invalid_rows['solution']) > 10:
                                            st.info(f"ä»– {len(invalid_rows['solution']) - 10}ä»¶...")
                            
                            # æœ‰åŠ¹ãªã‚«ãƒ†ã‚´ãƒªä¸€è¦§ã®è¡¨ç¤º
                            with st.expander("ğŸ“‹ å®šç¾©ã•ã‚Œã¦ã„ã‚‹æœ‰åŠ¹ãªã‚«ãƒ†ã‚´ãƒª", expanded=False):
                                col1, col2 = st.columns(2)
                                with col1:
                                    st.write("**èª²é¡Œåˆ†é¡ã‚«ãƒ†ã‚´ãƒª:**")
                                    for cat in problem_categories:
                                        st.write(f"â€¢ {cat}")
                                with col2:
                                    st.write("**è§£æ±ºæ‰‹æ®µåˆ†é¡ã‚«ãƒ†ã‚´ãƒª:**")
                                    for cat in solution_categories:
                                        st.write(f"â€¢ {cat}")
                        
                        # çµæœè¡¨ç¤ºã¨çµ±è¨ˆ
                        st.header("ğŸ“Š åˆ†é¡çµæœ")
                        
                        col1, col2 = st.columns(2)
                        with col1:
                            st.subheader("ğŸ¯ èª²é¡Œåˆ†é¡ã®åˆ†å¸ƒ")
                            p_counts = df['èª²é¡Œåˆ†é¡'].value_counts()
                            st.bar_chart(p_counts)
                        
                        with col2:
                            st.subheader("ğŸ”§ è§£æ±ºæ‰‹æ®µåˆ†é¡ã®åˆ†å¸ƒ")
                            s_counts = df['è§£æ±ºæ‰‹æ®µåˆ†é¡'].value_counts()
                            st.bar_chart(s_counts)
                        
                        # çµæœãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
                        st.subheader("ğŸ’¾ çµæœãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")
                        
                        # å•é¡Œã®ã‚ã‚‹è¡Œã«ãƒ•ãƒ©ã‚°ã‚’ä»˜ã‘ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
                        df_download = df.copy()
                        df_download['åˆ†é¡æ¤œè¨¼çµæœ'] = ''
                        
                        for item in invalid_rows['problem']:
                            idx = item['index'] - 1
                            df_download.at[idx, 'åˆ†é¡æ¤œè¨¼çµæœ'] = 'èª²é¡Œåˆ†é¡ã‚¨ãƒ©ãƒ¼'
                        
                        for item in invalid_rows['solution']:
                            idx = item['index'] - 1
                            if df_download.at[idx, 'åˆ†é¡æ¤œè¨¼çµæœ']:
                                df_download.at[idx, 'åˆ†é¡æ¤œè¨¼çµæœ'] += ', è§£æ±ºæ‰‹æ®µåˆ†é¡ã‚¨ãƒ©ãƒ¼'
                            else:
                                df_download.at[idx, 'åˆ†é¡æ¤œè¨¼çµæœ'] = 'è§£æ±ºæ‰‹æ®µåˆ†é¡ã‚¨ãƒ©ãƒ¼'
                        
                        output_buffer = io.BytesIO()
                        with pd.ExcelWriter(output_buffer, engine='openpyxl') as writer:
                            df_download.to_excel(writer, index=False, sheet_name='åˆ†é¡çµæœ')
                        
                        st.download_button(
                            label="ğŸ“¥ Excelãƒ•ã‚¡ã‚¤ãƒ«ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆæ¤œè¨¼çµæœä»˜ãï¼‰",
                            data=output_buffer.getvalue(),
                            file_name=f"classification_result_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                        )
                        
                    except Exception as e:
                        st.error(f"âŒ å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")
                        st.error("å‡¦ç†ã‚’ä¸­æ–­ã—ã¾ã—ãŸã€‚ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰å†é–‹ã§ãã¾ã™ã€‚")
                        
    except Exception as e:
        st.error(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}")

# ãƒ•ãƒƒã‚¿ãƒ¼
st.markdown("---")
st.markdown("### ğŸ”¬ PatentScope AI - GPT-4o-mini Edition")
st.markdown("**Powered by OpenAI GPT-4o-mini | å®‰å®šæ€§å‘ä¸Šç‰ˆ**")